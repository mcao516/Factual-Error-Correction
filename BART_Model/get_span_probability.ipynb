{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import string\n",
    "import torch.nn as nn\n",
    "\n",
    "from fairseq.models.bart import BARTModel\n",
    "from utils import read_lines, get_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart = BARTModel.from_pretrained('/home/ml/cadencao/Downloads/BART_models/bart.large.xsum',\n",
    "                                 checkpoint_file='model.pt',\n",
    "                                 data_name_or_path='/home/ml/cadencao/Downloads/BART_models/bart.large.xsum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- activate evaluation mode\n"
     ]
    }
   ],
   "source": [
    "bart.cuda()\n",
    "bart.eval()\n",
    "bart.half()\n",
    "print('- activate evaluation mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_func = bart.encode\n",
    "decode_func = bart.decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'fairseq.models.bart.model.BARTModel'>\n",
      "<class 'fairseq.models.transformer.TransformerEncoder'>\n",
      "<class 'fairseq.models.transformer.TransformerDecoder'>\n"
     ]
    }
   ],
   "source": [
    "bart_encoder = bart.model.encoder\n",
    "bart_decoder = bart.model.decoder\n",
    "print(type(bart.model))\n",
    "print(type(bart_encoder))\n",
    "print(type(bart_decoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read XSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11301\n"
     ]
    }
   ],
   "source": [
    "document_path = '/home/ml/cadencao/XSum/fairseq_files/test.source'\n",
    "target_path = '/home/ml/cadencao/XSum/fairseq_files/test.target'\n",
    "preds_path = 'preds/xsum_preds.hypo'\n",
    "xsum_source = read_lines(document_path)\n",
    "xsum_target = read_lines(target_path)\n",
    "xsum_preds = read_lines(preds_path)\n",
    "print(len(xsum_source))\n",
    "assert len(xsum_source) == len(xsum_target) == len(xsum_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "from fairseq.data.data_utils import collate_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 217])\n",
      "tensor([217], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "INDEX = 10066\n",
    "test_inputs = [xsum_source[INDEX]]\n",
    "src_tokens = collate_tokens([encode_func(i) for i in test_inputs], pad_idx=1, left_pad=True)\n",
    "src_tokens = src_tokens.cuda()\n",
    "print(src_tokens.shape)\n",
    "\n",
    "src_lengths = torch.sum(src_tokens != 1, dim=1)\n",
    "print(src_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_probs(sequence, document):\n",
    "    \"\"\"One sequence each time.\n",
    "    \"\"\"\n",
    "    inputs = [document]\n",
    "\n",
    "    # tokenization\n",
    "    src_tokens = collate_tokens([encode_func(i) for i in inputs], pad_idx=1, left_pad=True)\n",
    "    src_tokens = src_tokens.cuda()\n",
    "    src_lengths = torch.sum(src_tokens != 1, dim=1)\n",
    "    \n",
    "    tgt_prefix = torch.tensor([2], dtype=torch.long).cuda()\n",
    "    tgt_ids = encode_func(sequence).cuda()\n",
    "    tgt = torch.cat([tgt_prefix, tgt_ids], dim=0)\n",
    "\n",
    "    tgt_input = tgt[:-1].cuda()\n",
    "    tgt_output = tgt[1:].cuda()\n",
    "\n",
    "    # encoding\n",
    "    encoder_out = bart_encoder(src_tokens, src_lengths=src_lengths)\n",
    "\n",
    "    # decoding\n",
    "    decoder_outputs = bart_decoder(tgt_input.unsqueeze(0), encoder_out, features_only=False)\n",
    "    logits = decoder_outputs[0]\n",
    "    probs = F.softmax(logits, dim=2)\n",
    "\n",
    "    # gather selected token probabilities\n",
    "    token_probs = torch.gather(probs, 2, tgt_output.unsqueeze(0).unsqueeze(-1))\n",
    "    token_probs = token_probs.squeeze()\n",
    "    \n",
    "    assert token_probs.shape == tgt_ids.shape\n",
    "    return token_probs.tolist(), tgt_ids.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_probs, tgt_ids = get_sequence_probs(xsum_target[INDEX], xsum_source[INDEX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 00: Police (0.20)\n",
      "- 01:  investigating (0.25)\n",
      "- 02:  the (0.81)\n",
      "- 03:  disappearance (0.56)\n",
      "- 04:  of (0.90)\n",
      "- 05:  a (0.84)\n",
      "- 06:  man (0.73)\n",
      "- 07:  three (0.00)\n",
      "- 08:  months (0.66)\n",
      "- 09:  ago (0.90)\n",
      "- 10:  say (0.08)\n",
      "- 11:  they (0.60)\n",
      "- 12:  have (0.40)\n",
      "- 13:  yet (0.00)\n",
      "- 14:  to (0.89)\n",
      "- 15:  trace (0.02)\n",
      "- 16:  the (0.23)\n",
      "- 17:  sender (0.05)\n",
      "- 18:  of (0.90)\n",
      "- 19:  a (0.80)\n",
      "- 20:  letter (0.76)\n",
      "- 21:  claiming (0.22)\n",
      "- 22:  he (0.57)\n",
      "- 23:  was (0.54)\n",
      "- 24:  dead (0.78)\n",
      "- 25: . (0.77)\n"
     ]
    }
   ],
   "source": [
    "for i, (t, p) in enumerate(zip(tgt_ids[1:-1], token_probs[1:-1])):\n",
    "    token = decode_func(t.unsqueeze(-1))\n",
    "    print(\"- {:02d}: {} ({:.2f})\".format(i, token, p), end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target (Cardiff City) not found!!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [decode_func(i.unsqueeze(-1)) for i in tgt_ids[1:-1]]\n",
    "get_probability('Cardiff City', tokens, token_probs[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Police investigating the disappearance of a man three months ago say they have yet to trace the sender of a letter claiming he was dead.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xsum_target[INDEX]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hallucination Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "with open('hallucinated_span.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        samples.append(json.loads(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1431,\n",
       " 'ents': ['Middlesbrough', 'Federico', 'Fazio'],\n",
       " 'hallucinated': ['Federico']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_probs = []\n",
    "for s in samples:\n",
    "    # get sequence probability\n",
    "    token_probs, tgt_ids = get_sequence_probs(xsum_preds[s['id']], xsum_source[s['id']])\n",
    "    tokens = [decode_func(i.unsqueeze(-1)) for i in tgt_ids[1:-1]]\n",
    "    \n",
    "    # calculate probability\n",
    "    sp = {'id': s['id'], 'ents': [], 'non-hallucinated': [], 'hallucinated': []}\n",
    "    for e in s['ents']:\n",
    "        p = get_probability(e, tokens, token_probs[1:-1])\n",
    "        sp['ents'].append(p)\n",
    "        if e in s['hallucinated']:\n",
    "            sp['hallucinated'].append(p)\n",
    "        else:\n",
    "            sp['non-hallucinated'].append(p)\n",
    "    sample_probs.append(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 8805,\n",
       " 'ents': [0.24124312947969884, 0.29296875, 0.46588326897472143],\n",
       " 'non-hallucinated': [0.29296875, 0.46588326897472143],\n",
       " 'hallucinated': [0.24124312947969884]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "right, false = [], []\n",
    "for s in sample_probs:\n",
    "    false.extend(s['hallucinated'])\n",
    "    right.extend(s['non-hallucinated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hallucinated:\n",
      "- Num: 19\n",
      "- Avg: 0.10\n",
      "- Max: 0.26\n",
      "- Min: 0.01\n",
      "\n",
      "Non-hallucinated:\n",
      "- Num: 64\n",
      "- Avg: 0.52\n",
      "- Max: 0.94\n",
      "- Min: 0.13\n"
     ]
    }
   ],
   "source": [
    "print('Hallucinated:')\n",
    "print('- Num: {}'.format(len(false)))\n",
    "print('- Avg: {:.2f}'.format(sum(false) / len(false)))\n",
    "print('- Max: {:.2f}'.format(max(false)))\n",
    "print('- Min: {:.2f}'.format(min(false)))\n",
    "\n",
    "print('\\nNon-hallucinated:')\n",
    "print('- Num: {}'.format(len(right)))\n",
    "print('- Avg: {:.2f}'.format(sum(right) / len(right)))\n",
    "print('- Max: {:.2f}'.format(max(right)))\n",
    "print('- Min: {:.2f}'.format(min(right)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for s in sample_probs:\n",
    "#     print('{}: {}'.format(s['id'], s['hallucinated']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = []\n",
    "pred_prob = []\n",
    "pred_ner = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [00:03,  9.22it/s]\n"
     ]
    }
   ],
   "source": [
    "for s, sp in tqdm(zip(samples, sample_probs)):\n",
    "    assert s['id'] == sp['id']\n",
    "    assert len(s['ents']) == len(sp['ents'])\n",
    "    for i, e in enumerate(s['ents']):\n",
    "        # target\n",
    "        if e in s['hallucinated']:\n",
    "            target.append('hallucinated')\n",
    "        else:\n",
    "            target.append('consistent')\n",
    "        \n",
    "        # probability\n",
    "        if sp['ents'][i] <= 0.25:\n",
    "            pred_prob.append('hallucinated')\n",
    "        else:\n",
    "            pred_prob.append('consistent')\n",
    "            \n",
    "        # NER\n",
    "        source = xsum_source[s['id']]\n",
    "        source_ents = [e.text for e in nlp(source).ents]\n",
    "        if e not in source_ents:\n",
    "            pred_ner.append('hallucinated')\n",
    "        else:\n",
    "            pred_ner.append('consistent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(target) == len(pred_prob) == len(pred_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  consistent       0.96      0.83      0.89        64\n",
      "hallucinated       0.61      0.89      0.72        19\n",
      "\n",
      "   micro avg       0.84      0.84      0.84        83\n",
      "   macro avg       0.79      0.86      0.81        83\n",
      "weighted avg       0.88      0.84      0.85        83\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(target, pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  consistent       0.94      0.48      0.64        64\n",
      "hallucinated       0.34      0.89      0.49        19\n",
      "\n",
      "   micro avg       0.58      0.58      0.58        83\n",
      "   macro avg       0.64      0.69      0.57        83\n",
      "weighted avg       0.80      0.58      0.61        83\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(target, pred_ner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor([[    0, 32251,   559,   537,    16,    20,  1513, 11711,     6,  3028,\n",
    "          6513,  5576,  7864,     6,  3059,    19,   116,     2,  6323,  6730,\n",
    "          1952,    11,    20,  1513,    32,  3665,     7,     5,  6855,  1643,\n",
    "           215,    25,  3028,  6513,  5576,  7864,     6,  2668,  4436,   571,\n",
    "         11032,   324,     6,  4508,  2884,  4663,     8,  2150, 24266,     6,\n",
    "            53,    89,    32,    67,  6730,  1952,  3665,     7,     5,  4165,\n",
    "          1643,   215,    25,   871,  4802,  1417,  3239,     6,  4720,  5415,\n",
    "             6,  7730,   229, 12614,     8, 23710,   118,  4849,     4,     2],\n",
    "        [    0,  1121,  1824,     6,    99,  3164,     9, 32631,  1253,    58,\n",
    "            26,     7,    28,    11,  1327,   116,     2,  2765,  1824,     6,\n",
    "          5169,   207,     9, 32631,  1253,    58,   303,    11,  1327,     4,\n",
    "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which political party is The Times columnist, Daniel Finkelstein, associated with?Some columnists in The Times are connected to the Conservative Party such as Daniel Finkelstein, Tim Montgomerie, Matthew Parris and Matt Ridley, but there are also columnists connected to the Labour Party such as David Aaronovitch, Phil Collins, Oliver Kamm and Jenni Russell.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_func(torch.tensor([    0, 32251,   559,   537,    16,    20,  1513, 11711,     6,  3028,\n",
    "          6513,  5576,  7864,     6,  3059,    19,   116,     2,  6323,  6730,\n",
    "          1952,    11,    20,  1513,    32,  3665,     7,     5,  6855,  1643,\n",
    "           215,    25,  3028,  6513,  5576,  7864,     6,  2668,  4436,   571,\n",
    "         11032,   324,     6,  4508,  2884,  4663,     8,  2150, 24266,     6,\n",
    "            53,    89,    32,    67,  6730,  1952,  3665,     7,     5,  4165,\n",
    "          1643,   215,    25,   871,  4802,  1417,  3239,     6,  4720,  5415,\n",
    "             6,  7730,   229, 12614,     8, 23710,   118,  4849,     4,     2], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which political party is The Times columnist, Daniel Finkelstein, associated with?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_func(torch.tensor([    0, 32251,   559,   537,    16,    20,  1513, 11711,     6,  3028,\n",
    "          6513,  5576,  7864,     6,  3059,    19,   116,     2], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some columnists in The Times are connected to the Conservative Party such as Daniel Finkelstein, Tim Montgomerie, Matthew Parris and Matt Ridley, but there are also columnists connected to the Labour Party such as David Aaronovitch, Phil Collins, Oliver Kamm and Jenni Russell.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_func(torch.tensor([    0, 6323,  6730,\n",
    "          1952,    11,    20,  1513,    32,  3665,     7,     5,  6855,  1643,\n",
    "           215,    25,  3028,  6513,  5576,  7864,     6,  2668,  4436,   571,\n",
    "         11032,   324,     6,  4508,  2884,  4663,     8,  2150, 24266,     6,\n",
    "            53,    89,    32,    67,  6730,  1952,  3665,     7,     5,  4165,\n",
    "          1643,   215,    25,   871,  4802,  1417,  3239,     6,  4720,  5415,\n",
    "             6,  7730,   229, 12614,     8, 23710,   118,  4849,     4,     2], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' convicted itemsmonth If things coalition Ned in Overall disaster Mission250 inran won by'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_func(torch.tensor([0, 3828, 1964, 2151, 318, 383, 3782, 22309, 11, 7806, 4463, 7750, 5714, 11, 3917, 351, 30, 2], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
