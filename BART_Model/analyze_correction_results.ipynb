{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_source_path = '/home/ml/cadencao/Two-Steps-Summarization/datasets/cnn_dm/corrupted_nodup_files/test.source'\n",
    "test_target_path = '/home/ml/cadencao/Two-Steps-Summarization/datasets/cnn_dm/corrupted_nodup_files/test.target'\n",
    "test_meta_path = '/home/ml/cadencao/Two-Steps-Summarization/datasets/cnn_dm/corrupted_nodup_files/test.metadata'\n",
    "pred_file_path = 'preds/nodup_preds_bm1_cpbest2.hypo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_metadata(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_summaries(file_path):\n",
    "    lines = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            lines.append(line.strip())\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11490\n"
     ]
    }
   ],
   "source": [
    "sources = read_summaries(test_source_path)\n",
    "targets = read_summaries(test_target_path)\n",
    "print(len(sources))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11490\n",
      "{'claim': 'Marseille prosecutor says \"so far no videos weren\\'t used in the crash investigation\" despite media reports . Journalists at Bild and Paris Match are \"very confident\" the video clip is real, an editor says . Andreas Lubitz had informed his Lufthansa training school of an episode of severe depression, airline says .', 'label': 'INCORRECT', 'backtranslation': False, 'augmentation': 'NegateSentences', 'augmentation_span': [8, 9], 'noise': False}\n"
     ]
    }
   ],
   "source": [
    "meta_data = read_metadata(test_meta_path)\n",
    "print(len(meta_data))\n",
    "print(meta_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = read_summaries(pred_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(preds):\n",
    "    processed_preds = []\n",
    "    for p in preds:\n",
    "        if p[0] == p[1] or p[0] == '\"' or p[0] == \"'\":\n",
    "            processed_preds.append(p[1:])\n",
    "#         if (p[0] == '\"' or p[0] == \"'\") and p.count(p[0]) % 2 == 1:\n",
    "#             processed_preds.append(p[1:])\n",
    "#         elif p[0] == p[1]:\n",
    "#             processed_preds.append(p[1:])\n",
    "        else:\n",
    "            processed_preds.append(p)\n",
    "    return processed_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = post_process(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11490\n"
     ]
    }
   ],
   "source": [
    "print(len(predicts))\n",
    "assert len(sources) == len(targets) == len(meta_data) == len(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Metadata:\n",
      "{'claim': \"Gertrude Weaver became the world's oldest person last week\\xa0following the death of a 117-year-old woman in Japan . Waver died from complications due to pneumonia in Camden . She attributed her long life to treating others well and eating her own cooking . Weaver was born in Arkansas in 1898 and worked as a domestic helper . 115-year-old Jeralean Talley, of Detroit, is not now the world's oldest person .\", 'label': 'INCORRECT', 'backtranslation': False, 'augmentation': 'NegateSentences', 'augmentation_span': [71, 72], 'noise': False}\n",
      "- Corrupted:\n",
      "Gertrude Weaver became the world's oldest person last week following the death of a 117-year-old woman in Japan . Waver died from complications due to pneumonia in Camden . She attributed her long life to treating others well and eating her own cooking . Weaver was born in Arkansas in 1898 and worked as a domestic helper . 115-year-old Jeralean Talley, of Detroit, is not now the world's oldest person . \n",
      "- Target:\n",
      "Gertrude Weaver became the world's oldest person last week following the death of a 117-year-old woman in Japan . Waver died from complications due to pneumonia in Camden . She attributed her long life to treating others well and eating her own cooking . Weaver was born in Arkansas in 1898 and worked as a domestic helper . 115-year-old Jeralean Talley, of Detroit, is now the world's oldest person .\n",
      "- Prediction:\n",
      "Gertrude Weaver became the world's oldest person last week following the death of a 117-year-old woman in Japan . Waver died from complications due to pneumonia in Camden . She attributed her long life to treating others well and eating her own cooking . Weaver was born in Arkansas in 1898 and worked as a domestic helper . 115-year.-old Jeralean Talley, of Detroit, is now the world't oldest person .\n"
     ]
    }
   ],
   "source": [
    "index = len(sources) // 2\n",
    "print('- Metadata:')\n",
    "print(meta_data[index])\n",
    "print('- Corrupted:')\n",
    "print(sources[index][: sources[index].find('</s>')])\n",
    "print('- Target:')\n",
    "print(targets[index])\n",
    "print('- Prediction:')\n",
    "print(predicts[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels, pred_labels = [], []\n",
    "for i, (m, p, s) in enumerate(zip(meta_data, predicts, sources)):\n",
    "    if m['label'] == \"CORRECT\":\n",
    "        true_labels.append(1)\n",
    "    else:\n",
    "        true_labels.append(0)\n",
    "    \n",
    "    s = s[: s.find('</s>') - 1]\n",
    "    p_tokens = p.lower().split()\n",
    "    s_tokens = s.lower().split()\n",
    "\n",
    "    if p_tokens == s_tokens:  # does not change source: predict correct\n",
    "        pred_labels.append(1)\n",
    "    else:\n",
    "        pred_labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 0, 1, 1, 0, 1, 1]\n",
      "[0, 1, 1, 0, 0, 0, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(true_labels[:10])\n",
    "print(pred_labels[:10])\n",
    "assert len(true_labels) == len(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Corrupted       0.78      0.95      0.86      5780\n",
      "Not Corrupted       0.93      0.73      0.82      5710\n",
      "\n",
      "    micro avg       0.84      0.84      0.84     11490\n",
      "    macro avg       0.86      0.84      0.84     11490\n",
      " weighted avg       0.86      0.84      0.84     11490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Corrupted', 'Not Corrupted']\n",
    "print(classification_report(true_labels, pred_labels, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String Matching Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_num = 0\n",
    "clean_match, corrupt_match = [], []\n",
    "\n",
    "for i, (m, s, t, p) in enumerate(zip(meta_data, sources, targets, predicts)):    \n",
    "#     if p[0] == p[1] or p[0] == '\"' or p[0] == \"'\":\n",
    "#         p = p[1:]\n",
    "\n",
    "    s = s[: s.find('</s>') - 1]\n",
    "    t_tokens = t.split()\n",
    "    p_tokens = p.split()\n",
    "\n",
    "#     if len(p_tokens) > len(t_tokens):\n",
    "#         p_tokens = p_tokens[: len(t_tokens)]\n",
    "\n",
    "    pred_correct = (t_tokens == p_tokens)\n",
    "    if pred_correct:\n",
    "        match_num += 1\n",
    "\n",
    "    if m['label'] == 'CORRECT':\n",
    "        clean_match.append(pred_correct)\n",
    "    else:\n",
    "        corrupt_match.append(pred_correct)\n",
    "#     else:\n",
    "#         if print_count < 10 and s != t:\n",
    "#             print('Metadata:')\n",
    "#             print(m)\n",
    "#             print('Inference:')\n",
    "#             print(t)\n",
    "#             print('Corrupted:')\n",
    "#             print(s)\n",
    "#             print('Prediction:')\n",
    "#             print(p)\n",
    "#             print()\n",
    "#             print_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6537859007832898"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_num / len(targets)  # 0.6504786771105309"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7094570928196147"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(clean_match) / len(clean_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5987889273356402"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(corrupt_match) / len(corrupt_match)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
