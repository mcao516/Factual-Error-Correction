{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fairseq.models.bart import BARTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart = BARTModel.from_pretrained('/home/ml/cadencao/Downloads/BART_models/bart.large.xsum',\n",
    "                                 checkpoint_file='model.pt',\n",
    "                                 data_name_or_path='/home/ml/cadencao/Downloads/BART_models/bart.large.xsum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- activate evaluation mode\n"
     ]
    }
   ],
   "source": [
    "bart.cuda()\n",
    "bart.eval()\n",
    "bart.half()\n",
    "print('- activate evaluation mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_func = bart.encode\n",
    "decode_func = bart.decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'fairseq.models.bart.model.BARTModel'>\n",
      "<class 'fairseq.models.transformer.TransformerEncoder'>\n",
      "<class 'fairseq.models.transformer.TransformerDecoder'>\n"
     ]
    }
   ],
   "source": [
    "bart_encoder = bart.model.encoder\n",
    "bart_decoder = bart.model.decoder\n",
    "print(type(bart.model))\n",
    "print(type(bart_encoder))\n",
    "print(type(bart_decoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read XSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lines(file_path):\n",
    "    files = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            files.append(line.strip())\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11301\n"
     ]
    }
   ],
   "source": [
    "document_path = '/home/ml/cadencao/XSum/fairseq_files/test.source'\n",
    "target_path = '/home/ml/cadencao/XSum/fairseq_files/test.target'\n",
    "xsum_source = read_lines(document_path)\n",
    "xsum_target = read_lines(target_path)\n",
    "print(len(xsum_source))\n",
    "assert len(xsum_source) == len(xsum_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import rouge\n",
    "\n",
    "from fairseq.data.data_utils import collate_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation with Avg\n"
     ]
    }
   ],
   "source": [
    "def prepare_results(p, r, f):\n",
    "    return '\\t{}:\\t{}: {:5.2f}\\t{}: {:5.2f}\\t{}: {:5.2f}'.format(metric, 'P', 100.0 * p, 'R', 100.0 * r, 'F1', 100.0 * f)\n",
    "\n",
    "aggregator = 'Avg'\n",
    "apply_avg = aggregator == 'Avg'\n",
    "apply_best = aggregator == 'Best'\n",
    "print('Evaluation with {}'.format(aggregator))\n",
    "\n",
    "evaluator = rouge.Rouge(metrics=['rouge-n', 'rouge-l', 'rouge-w'],\n",
    "                        max_n=4,\n",
    "                        limit_length=True,\n",
    "                        length_limit=100,\n",
    "                        length_limit_type='words',\n",
    "                        apply_avg=apply_avg,\n",
    "                        apply_best=apply_best,\n",
    "                        alpha=0.5, # Default F1_score\n",
    "                        weight_factor=1.2,\n",
    "                        stemming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 589])\n",
      "tensor([589], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "INDEX = 1819\n",
    "test_inputs = [xsum_source[INDEX]]\n",
    "src_tokens = collate_tokens([encode_func(i) for i in test_inputs], pad_idx=1, left_pad=True)\n",
    "src_tokens = src_tokens.cuda()\n",
    "print(src_tokens.shape)\n",
    "\n",
    "src_lengths = torch.sum(src_tokens != 1, dim=1)\n",
    "print(src_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([589, 1, 1024])\n"
     ]
    }
   ],
   "source": [
    "encoder_out = bart_encoder(src_tokens, src_lengths=src_lengths)\n",
    "print(encoder_out.encoder_out.shape)  # [seq_len, batch_size, hidden_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 00: The (0.47)\n",
      "- 01:  brother (0.78)\n",
      "- 02:  of (0.92)\n",
      "- 03:  a (0.59)\n",
      "- 04:  victim (0.47)\n",
      "- 05:  of (0.92)\n",
      "- 06:  Bloody (0.73)\n",
      "- 07:  Sunday (0.93)\n",
      "- 08:  has (0.88)\n",
      "- 09:  said (0.19)\n",
      "- 10:  a (0.39)\n",
      "- 11:  planned (0.32)\n",
      "- 12:  march (0.57)\n",
      "- 13:  by (0.86)\n",
      "- 14:  veterans (0.32)\n",
      "tensor([[  7,  11,   9, 333, 108]], device='cuda:0')\n",
      "- 15:  in (0.12)\n",
      "- 16:  L (0.69)\n",
      "- 17: ond (0.86)\n",
      "- 18: ond (0.92)\n",
      "- 19: erry (0.96)\n",
      "- 20:  is (0.46)\n",
      "- 21:  an (0.40)\n",
      "- 22:  \" (0.71)\n",
      "- 23: act (0.70)\n",
      "- 24:  of (0.92)\n",
      "- 25:  pure (0.89)\n",
      "- 26:  provocation (0.96)\n",
      "- 27: \". (0.69)\n",
      "- 28:  (0.91)\n",
      "torch.Size([30, 589])\n"
     ]
    }
   ],
   "source": [
    "init_input = torch.tensor([[2, 0]] * src_tokens.shape[0], dtype=torch.long).cuda()\n",
    "min_decode_step, max_decode_step, pad_id, eos_id = 10, 50, 1, 2\n",
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "for step in range(max_decode_step):\n",
    "    decoder_outputs = bart_decoder(init_input, encoder_out, features_only=False)\n",
    "    logits = decoder_outputs[0][:, -1, :]  # [batch_size, vocab]\n",
    "    probs = softmax(logits)\n",
    "    assert logits.shape == probs.shape\n",
    "    attn = decoder_outputs[1]['attn'][0]  # [batch_size, prev_token_len, src_token_len]\n",
    "    assert logits.dim() == 2 and attn.dim() == 3\n",
    "    logits[:, pad_id] = -math.inf  # never select pad\n",
    "    probs[:, pad_id] = 0.0  # never select pad\n",
    "\n",
    "    if step + 1 < min_decode_step:\n",
    "        logits[:, eos_id] = -math.inf\n",
    "\n",
    "    # preds = torch.argmax(logits, dim=1)\n",
    "    value, indices = torch.topk(probs, 5, dim=1)\n",
    "    selected_token = indices[:, 0]\n",
    "\n",
    "    if step == 15:\n",
    "        print(indices)\n",
    "        selected_token = indices[:, 1]\n",
    "    elif step == 19:\n",
    "        selected_token = indices[:, 0]\n",
    "    elif step == 19:\n",
    "        selected_token = indices[:, 0]\n",
    "\n",
    "    init_input = torch.cat([init_input, selected_token.unsqueeze(1)], dim=-1)\n",
    "    print(\"- {:02d}: {} ({:.2f})\".format(step, decode_func(selected_token), probs.squeeze()[selected_token.item()]), end='\\n')\n",
    "\n",
    "    if selected_token.item() == eos_id:\n",
    "        break\n",
    "\n",
    "print(attn[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,     0,   133,  2138,     9,    10,  1802,     9, 38274,   395,\n",
       "            34,    26,    10,  1904,  6674,    30,  4823,    11,   226,  2832,\n",
       "          2832, 11228,    16,    41,    22,  7257,     9,  8309, 29995,   845,\n",
       "             2]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The brother of one of the victims of Bloody Sunday has said a planned march by former soldiers in Londonderry is an \"act of pure provocation\".'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_func(torch.tensor([0,   133,  2138,     9,    65,     9,     5,  1680,     9, 38274,   395,    34,    26,    10,  1904,  6674,    30,   320,  3878,          11,   226,  2832,  2832, 11228,    16,    41,    22,  7257,     9,         8309, 29995,   845,     2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The brother of one of the victims of Bloody Sunday has said a planned march by former soldiers in Londonderry is \"an act of pure provocation\".'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_func(torch.tensor([ 0, 133, 2138, 9, 65, 9, 5, 1680, 9, 38274,   395,    34,    26,    10,  1904,  6674,    30,   320,  3878, 11,   226,  2832,  2832, 11228,    16,    22,   260,  1760,     9, 8309, 29995,   845,     2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The brother of one of the victims of Bloody Sunday has said a planned march by former soldiers in Londonderry is an \"act of pure provocation\"'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_func(torch.tensor([0,   133,  2138,     9,    65,     9,     5,  1680,     9, 38274,   395,    34,    26,    10,  1904,  6674,    30,   320,  3878, 11,   226,  2832,  2832, 11228,    16,    41,    22,  7257,     9, 8309, 29995,   113, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The brother of a victim of Bloody Sunday has said a planned march by veterans in Londonderry is an \"act of pure provocation\".\n"
     ]
    }
   ],
   "source": [
    "hypothesis = decode_func(init_input[0])\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Relatives of Bloody Sunday victims have called a march by military veterans in Londonderry \"an act of pure provocation\".'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xsum_target[INDEX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\trouge-1:\tP: 65.22\tR: 78.95\tF1: 71.43\n",
      "\trouge-2:\tP: 40.91\tR: 50.00\tF1: 45.00\n",
      "\trouge-3:\tP: 23.81\tR: 29.41\tF1: 26.32\n",
      "\trouge-4:\tP: 10.00\tR: 12.50\tF1: 11.11\n",
      "\trouge-l:\tP: 66.12\tR: 77.53\tF1: 71.37\n",
      "\trouge-w:\tP: 51.90\tR: 34.86\tF1: 41.71\n"
     ]
    }
   ],
   "source": [
    "all_hypothesis = [hypothesis]\n",
    "all_references = [xsum_target[INDEX]]\n",
    "\n",
    "scores = evaluator.get_scores(all_hypothesis, all_references)\n",
    "\n",
    "for metric, results in sorted(scores.items(), key=lambda x: x[0]):\n",
    "    print(prepare_results(results['p'], results['r'], results['f']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The brother of a victim of Bloody Sunday has said a planned march by veterans in Londonderry is an \"act of pure provocation\".\n",
      "(Bloody Sunday, Londonderry)\n"
     ]
    }
   ],
   "source": [
    "out = nlp(decode_func(init_input[0]))\n",
    "print(out)\n",
    "print(out.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The body of a man whose body was found at the site of the Swansea Bay Power Station collapse has been removed from the site.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"The body of a man whose body was found at the site of the Swansea Bay Power Station collapse has been removed from the site.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The body of a man who died when the collapsed Swansea Power Station building collapsed has been removed from the site.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"The body of a man who died when the collapsed Swansea Power Station building collapsed has been removed from the site.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Christopher Huxtable, 34, from Swansea, had been missing since the collapse in February. His body was found on Wednesday and workers who carried out the search formed a guard of honour as it was driven from the site in the early hours of the morning. Ken Cresswell, 57, and John Shaw, 61, both from Rotherham, remain missing. The body of a fourth man, Michael Collings, 53, from Brotton, Teesside, was previously recovered from the site. Swansea East MP Carolyn Harris, who has been involved with the family since the incident, said they still did not know all the facts about the collapse. She said: \"I feel very sad. My heart and my prayers go out to the family who have waited desperately for Christopher\\'s body to be found. They can finally have closure, and say goodbye to him and grieve his loss. \"But let\\'s not forget that there\\'s two other families who are still waiting for their loved ones to be returned.\" The building was due for demolition when it partially collapsed in February.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xsum_source[6220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15338,  3864,  9368"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' tower'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_func(torch.tensor([9368]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
