{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from fairseq.models.bart import BARTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart = BARTModel.from_pretrained('/home/ml/cadencao/Downloads/BART_models/checkpoints_uni',\n",
    "                                 checkpoint_file='checkpoint_best.pt',\n",
    "                                 data_name_or_path='/home/ml/cadencao/Two-Steps-Summarization/datasets/cnn_dm/corrupted_nodup_files/cnn_dm-bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- activate evaluation mode\n"
     ]
    }
   ],
   "source": [
    "bart.cuda()\n",
    "bart.eval()\n",
    "print('- activate evaluation mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_func = bart.encode\n",
    "decode_func = bart.decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'fairseq.models.bart.model.BARTModel'>\n",
      "<class 'fairseq.models.transformer.TransformerEncoder'>\n",
      "<class 'fairseq.models.transformer.TransformerDecoder'>\n"
     ]
    }
   ],
   "source": [
    "bart_encoder = bart.model.encoder\n",
    "bart_decoder = bart.model.decoder\n",
    "print(type(bart.model))\n",
    "print(type(bart_encoder))\n",
    "print(type(bart_decoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq.data.data_utils import collate_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = ['Membership gives the ICC jurisdiction over alleged crimes committed in Palestinian territories since last June . Israel and the United States opposed the move, which could open the door to war crimes investigations against Israelis . </s> (CNN)The Palestinian Authority officially became the 123rd member of the International Criminal Court on Wednesday, a step that gives the court jurisdiction over alleged crimes in Palestinian territories. The formal accession was marked with a ceremony at The Hague, in the Netherlands, where the court is based. The Palestinians signed the ICC\\'s founding Rome Statute in January, when they also accepted its jurisdiction over alleged crimes committed \"in the occupied Palestinian territory, including East Jerusalem, since June 13, 2014.\" Later that month, the ICC opened a preliminary examination into the situation in Palestinian territories, paving the way for possible war crimes investigations against Israelis. As members of the court, Palestinians may be subject to counter-charges as well. Israel and the United States, neither of which is an ICC member, opposed the Palestinians\\' efforts to join the body. But Palestinian Foreign Minister Riad al-Malki, speaking at Wednesday\\'s ceremony, said it was a move toward greater justice. \"As Palestine formally becomes a State Party to the Rome Statute today, the world is also a step closer to ending a long era of impunity and injustice,\" he said, according to an ICC news release. \"Indeed, today brings us closer to our shared goals of justice and peace.\" Judge Kuniko Ozaki, a vice president of the ICC, said acceding to the treaty was just the first step for the Palestinians. \"As the Rome Statute today enters into force for the State of Palestine, Palestine acquires all the rights as well as responsibilities that come with being a State Party to the Statute. These are substantive commitments, which cannot be taken lightly,\" she said. Rights group Human Rights Watch welcomed the development. \"Governments seeking to penalize Palestine for joining the ICC should immediately end their pressure, and countries that support universal acceptance of the court\\'s treaty should speak out to welcome its membership,\" said Balkees Jarrah, international justice counsel for the group. \"What\\'s objectionable is the attempts to undermine international justice, not Palestine\\'s decision to join a treaty to which over 100 countries around the world are members.\" In January, when the preliminary ICC examination was opened, Israeli Prime Minister Benjamin Netanyahu described it as an outrage, saying the court was overstepping its boundaries. The United States also said it \"strongly\" disagreed with the court\\'s decision. \"As we have said repeatedly, we do not believe that Palestine is a state and therefore we do not believe that it is eligible to join the ICC,\" the State Department said in a statement. It urged the warring sides to resolve their differences through direct negotiations. \"We will continue to oppose actions against Israel at the ICC as counterproductive to the cause of peace,\" it said. But the ICC begs to differ with the definition of a state for its purposes and refers to the territories as \"Palestine.\" While a preliminary examination is not a formal investigation, it allows the court to review evidence and determine whether to investigate suspects on both sides. Prosecutor Fatou Bensouda said her office would \"conduct its analysis in full independence and impartiality.\" The war between Israel and Hamas militants in Gaza last summer left more than 2,000 people dead. The inquiry will include alleged war crimes committed since June. The International Criminal Court was set up in 2002 to prosecute genocide, crimes against humanity and war crimes. CNN\\'s Vasco Cotovio, Kareem Khadder and Faith Karimi contributed to this report.',\n",
    "               'LZ: Indiana law pushing back LGBT rights, and other states\\' anti-LGBT moves, bow to far right wing that GOP candidates need for 2016 . Cruz, Huckabee, Jindal, Carson, Walker are reviving culture wars, he says.  Equality for LGBT has not yet \"won\" in America . </s> (CNN)A year ago Bloomberg published a story with the following headline: Mike Pence, a Koch Favorite, Mulls 2016 Run for President. The story ticked off items on Pence\\'s conservative things-to-do list while also noting his close ties to the deep-pocketed Koch brothers, as well as other right-wing lobbying groups. Last August the Indiana governor was in Dallas for an Americans for Prosperity event; the group is backed by the conservative Koch brothers, and supported Gov. Pence\\'s tax-slashing budget. Now, Pence is drawing huge heat for his controversial decision to sign a religious freedom law last week that opens the door to discrimination against gays and lesbians.  Why would Pence ignore the pleas of Indiana\\'s Chamber of Commerce as well as the Republican mayor of his state capital and sign such a bill? Because there\\'s a very powerful wing of his party that wants a conservative as its 2016 candidate and this bill was Pence\\'s way of shoring up his street cred. It is also the reason why Republican Jeb Bush, Pence\\'s fellow White House hopeful, who is viewed as a little light in that category, was first to rush in to defend Pence and the law. One lesson here: Just because more than 70% of the country now lives in states where same-sex marriage is legal does not mean 70% of the country is happy about it. Backlash aside, the fact is Pence has scored a lot of points this week among ultraconservatives. And while that may not be enough to get him over this political hump, the very public debate that now embroils him â€” and Arkansas Gov.  Asa Hutchinson, and likely 14 other states considering similar proposals this year -- is more than enough to drag the entire Republican field farther to the right than the party had hoped. Pence: \\'Was I expecting this kind of backlash? Heavens no.\\' For there is no way a Republican can get through the pending primary without denouncing LGBT rights, which unfortunately will turn numerous Americans into single-issue voters. I foolishly hoped the issue of LGBT rights would be a bit player in the 2016 general election, overshadowed by foreign policy and the economy. Instead it looks like it\\'s going to be dragged down to a replay of Pat Buchanan\\'s \"cultural war\" speech, during which he told the 1992 Republican National Convention: \"We stand with (George H.W. Bush) against the amoral idea that gay and lesbian couples should have the same standing in law as married men and women\" and later followed with \"There is a religious war going on in this country. It is a cultural war, as critical to the kind of nation we shall be as the Cold War itself. For this war is for the soul of America.\" Progressives may enjoy watching Pence\\'s temporary fall from grace, but his policy rhetoric has echoed that of 2016 hopeful Sen. Ted Cruz of Texas, who has indicated a federal ban on same-sex marriage is not off the GOP table. And even if you think neither Pence nor Bush nor Cruz will win the nomination, someone has to. In light of that, listen to conservative former Arkansas Gov.',\n",
    "               'College-bound basketball star asks girl with Down syndrome to high school prom . Pictures of the two during the \"prom-posal\" have not gone viral . </s> (CNN)He\\'s a blue chip college basketball recruit. She\\'s a high school freshman with Down syndrome. At first glance Trey Moses and Ellie Meredith couldn\\'t be more different. But all that changed Thursday when Trey asked Ellie to be his prom date. Trey -- a star on Eastern High School\\'s basketball team in Louisville, Kentucky, who\\'s headed to play college ball next year at Ball State -- was originally going to take his girlfriend to Eastern\\'s prom. So why is he taking Ellie instead? \"She\\'s great... she listens and she\\'s easy to talk to\" he said. Trey made the prom-posal (yes, that\\'s what they are calling invites to prom these days) in the gym during Ellie\\'s P.E. class. Trina Helson, a teacher at Eastern, alerted the school\\'s newspaper staff to the prom-posal and posted photos of Trey and Ellie on Twitter that have gone viral. She wasn\\'t surpristed by Trey\\'s actions. \"That\\'s the kind of person Trey is,\" she said. To help make sure she said yes, Trey entered the gym armed with flowers and a poster that read \"Let\\'s Party Like it\\'s 1989,\" a reference to the latest album by Taylor Swift, Ellie\\'s favorite singer. Trey also got the OK from Ellie\\'s parents the night before via text. They were thrilled. \"You just feel numb to those moments raising a special needs child,\"  said Darla Meredith, Ellie\\'s mom. \"You first feel the need to protect and then to overprotect.\" Darla Meredith said Ellie has struggled with friendships since elementary school, but a special program at Eastern called Best Buddies had made things easier for her. She said Best Buddies cultivates friendships between students with and without developmental disabilities and prevents students like Ellie from feeling isolated and left out of social functions. \"I guess around middle school is when kids started to care about what others thought,\" she said, but \"this school, this year has been a relief.\" Trey\\'s future coach at Ball State, James Whitford, said he felt great about the prom-posal, noting that Trey, whom he\\'s known for a long time, often works with other kids . Trey\\'s mother, Shelly Moses, was also proud of her son. \"It\\'s exciting to bring awareness to a good cause,\" she said. \"Trey has worked pretty hard, and he\\'s a good son.\" Both Trey and Ellie have a lot of planning to do. Trey is looking to take up special education as a college major, in addition to playing basketball in the fall. As for Ellie, she can\\'t stop thinking about prom. \"Ellie can\\'t wait to go dress shopping\" her mother said. \"Because I\\'ve only told about a million people!\" Ellie interjected.',\n",
    "               'Richie Benaud first earned fame as a cricket player, later as broadcaster . Prime Minister Tony Abbott calls them \"a cricketing champion and Australian icon\" </s> (CNN)Former Australia cricket captain and legendary broadcaster Richie Benaud has died at the age of 84. Benaud, whose witty one-liners from the commentary box resonated far beyond Australia\\'s shores, said last year he was being treated for skin cancer. \"After Don Bradman, there has been no Australian player more famous than Richie Benaud,\" Cricket Australia said on its website. \"Benaud stood at the top of the game throughout his rich life, first as a record-breaking leg-spinner and captain, and then as cricket\\'s most famous -- and most impersonated -- broadcaster.\" A veteran of 64 Test matches, Benaud was inducted into the Sport Australia Hall of Fame in 1985. While many regarded his voice as the soundtrack to an Australian summer, Benaud was equally revered by the cricketing public on the other side of the world where he spent more than four decades with the BBC taking the game into millions of British living rooms. But whether you were sitting in Sydney or in South London, there were plenty of \"marvelous\" Richie moments from the box to savor: . \"And Glenn McGrath dismissed for two, just ninety-eight runs short of his century.\" \"From our broadcasting box you can\\'t see any grass at all. It is simply a carpet of humanity.\" \"Captaincy is 90% luck and 10% skill. But don\\'t try it without that 10%.\" News of his passing quickly generated a wave of condolences, including from Australian Prime Minister Tony Abbott. \"To most Australians Richie Benaud was cricket. He personified its traditions and its values,\" Abbott said in a written statement Friday. \"While many Australians only know Richard Benaud as the voice of cricket, we should not forget that in his day he was a cricketer with few equals. It was why he was so insightful as a commentator. \"As a player his record has withstood the test of time.  He led the Australian side from 1958/59 through to 1963/1964, never losing a series in his 28 Tests as captain. \"As captain, he was first to lead a full Australian tour to India and Pakistan in 1959/60. He was the first cricketer to reach a Test double of 2,000 runs and 200 wickets. \"Given the special place Richie Benaud has in our national life, I have asked that on the day of his funeral flags fly at half-mast. I extend my condolences and the condolences of the Australian people, to his wife Daphne and his family and friends. Current Australian captain Michael Clarke posted an image of Benaud on Instagram with the message: \"What a man. Extremely sad day. You were a lot more then just a cricketer Richie. RIP.\" Clarke\\'s former teammate Shane Warne also took to Instagram to post a touching letter to the late commentator. He wrote: \"Dear Richie, I\\'ve known you & Daphne for close to 30 years & to everyone you were a legend on all levels & rightly so too. \"As a cricketer, commentator & as a person, you were the best there\\'s ever been & to top it off, an absolute gentleman... For me it was an honour & a privilege to call you a close friend & mentor, we had so many wonderful times together, talking cricket & in particular, our love & passion of leg spin bowling. \"I will cherish our entertaining dinners & all the fun times we shared over a long period of time. I would also like to thank you & Daphne for all your support & time you made for me as a young cricketer & leg spin bowler trying to make his way as an 18 year old, your tips & advice along the journey meant so much !!! \"Richie, you were loved by everyone, not just the cricket family, you were the godfather of cricket & you will be missed by all... R.I.P my friend.\" Benaud, who was born in 1930 in Penrith, New South Wales, lead Australia into an era of world dominance as a player. But it was after he hung up his spikes that his legendary status was confirmed. Writing in a column in The Australian, cricket writer Gideon Haigh wrote \"television was Benaud\\'s calling, suiting his captain\\'s spontaneity and intuition. \"He was authoritative but not pedantic, dignified but not pompous, and never spoke unless he had something to say. He was so popular that many humorists strove to imitate him, so distinctive that none ever quite got him right.\" The BBC\\'s cricket correspondent Jonathan Agnew agreed. \"He was quite simply peerless. Nobody else had his authority, popularity and skill,\" Agnew said in a column on the BBC website. \"If you speak to any broadcaster from any sport, they will point to Richie as the standard-bearer.\" Australian national team coach Darren Lehmann said Benaud set \"an incredibly high standard on and off the field.\" \"The fact that Australia never lost a series under his captaincy says so much and those standards were just as high when he turned his attention to calling the game,\" he told cricket.com.au. \"We loved listening to him commentate when the team was together in the dressing room. When he was on air, we always had the TV volume turned up because his comments were so insightful.\" Benaud\\'s passing also drew messages of sympathy on social media from beyond his native Australia. Imran Khan, the former captain of Pakistan and now a leading politician there, tweeted: \"Saddened by the death of Richie Benaud, one of the greatest cricketing brains.\" While Kumar Sangakkara, the current captain of Sri Lanka\\'s Test team, posted: \"So sad to hear about the passing of Richie Benaud. The great voice of cricket is no more. He defined an era with conviction and sincerity.\" British Prime Minister David Cameron tweeted: \"I grew up listening to Richie Benaud\\'s wonderful cricket commentary. Like all fans of the sport, I will miss him very much.\" CNN\\'s Pierre Meilhan and Azadeh Ansari contributed to this report.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorting(lst): \n",
    "    lst2 = sorted(lst, key=len) \n",
    "    return lst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = sorting(test_inputs)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Richie Ben', 'Membership']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s[:10] for s in test_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokens = collate_tokens([encode_func(i) for i in test_inputs], pad_idx=1, left_pad=True)\n",
    "src_tokens = src_tokens.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 28295,   324,  ...,    25,     5,     2],\n",
       "        [    1,     1,     1,  ...,   266,     4,     2]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(src_tokens.shape)\n",
    "src_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1024,  735], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_lengths = torch.sum(src_tokens != 1, dim=1)\n",
    "src_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_out = bart_encoder(src_tokens, src_lengths=src_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_input = torch.tensor([[2, 0]] * src_tokens.shape[0], dtype=torch.long).cuda()\n",
    "min_decode_step, max_decode_step, pad_id, eos_id = 30, 80, 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 7.93 GiB total capacity; 7.00 GiB already allocated; 4.06 MiB free; 7.44 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-2dce5514f029>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_decode_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdecoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbart_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# [batch_size, seq_len, vocab]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m  \u001b[0;31m# never select pad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fairseq/fairseq/models/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, prev_output_tokens, encoder_out, incremental_state, features_only, alignment_layer, alignment_heads, src_lengths, return_all_hiddens)\u001b[0m\n\u001b[1;32m    703\u001b[0m         )\n\u001b[1;32m    704\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfeatures_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fairseq/fairseq/models/transformer.py\u001b[0m in \u001b[0;36moutput_layer\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0;31m# project back to size of vocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshare_input_output_embed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py37/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 7.93 GiB total capacity; 7.00 GiB already allocated; 4.06 MiB free; 7.44 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "for step in range(max_decode_step):\n",
    "    decoder_outputs = bart_decoder(init_input, encoder_out, features_only=False)\n",
    "    logits = decoder_outputs[0][:, -1, :]  # [batch_size, seq_len, vocab]\n",
    "    assert logits.dim() == 2\n",
    "    logits[:, pad_id] = -math.inf  # never select pad\n",
    "    \n",
    "    if step + 1 < min_decode_step:\n",
    "        logits[:, eos_id] = -math.inf\n",
    "    \n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    init_input = torch.cat([init_input, preds.unsqueeze(1)], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.tensor([0, 28165,    12,  4092,  2613,   999,  6990,  1816,\n",
    "            19,  5818, 14115,     7,   239,   334, 12206,   479, 12290,     9,\n",
    "             5,    80,   148,     5,    22, 12501,    12, 30999,   113,    33,\n",
    "          1613,  7696,   479,     2], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_func(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LZ: Indiana law pushing back LGBT rights, and other states\\' anti-LGBT moves, bow to far right wing that GOP candidates need for 2016 .\n",
    "# Cruz, Huckabee, Jindal, Carson, Walker are reviving culture wars, he says.  Equality for LGBT has not yet \"won\" in America .\n",
    "\n",
    "# LZ: Indiana law pushing back LGBT rights, and other states' anti-LGBT moves, bow to far right wing that GOP candidates need for 2016 .\n",
    "# Cruz, Huckabee, Jindal, Carson, Walker are reviving culture wars, he says.  Equality for LGBT has not yet \"won\" in America .\n",
    "\n",
    "# Membership gives the ICC jurisdiction over alleged crimes committed in Palestinian territories since last June .\n",
    "# Israel and the United States opposed the move, which could open the door to war crimes investigations against Israelis .\n",
    "\n",
    "# Membership gives the ICC jurisdiction over alleged crimes committed in Palestinian territories since last June .\n",
    "# Israel and the United States opposed the move, which could open the door to war crimes investigations against Israelis ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_func(\"Membership gives the ICC jurisdiction over alleged crimes committed in Palestinian territories since last June . Israel and the United States opposed the move, which could open the door to war crimes investigations against Israelis .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_func(torch.tensor([    0,   108, 28165,    12,  4092,  2613,   999,  6990,  1816,    19,\n",
    "         5818, 14115,     7,   239,   334, 12206,   479, 12290,     9,     5,\n",
    "           80,   148,     5,    22, 12501,    12, 30999,   113,    33,  1613,\n",
    "         7696,   479,     2], device='cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marseille prosecutor says \"so far no videos were used in the crash investigation\" despite media reports . \n",
    "# Journalists at Bild and Paris Match are \"very confident\" the video clip is real, an editor says . \n",
    "# Andreas Lubitz had informed his Lufthansa training school of an episode of severe depression, airline says ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prev_output_tokens\n",
    "tensor([[    2,   487,  5649,  1910, 23551,   636,     8,  5716, 28855,    33,\n",
    "           258,    56,  2129,  2012,     7,     5,   191,   479, 23551,   636,\n",
    "          1770,  3870,    11,    10,   130,    12,   180,   432,    42,  1035,\n",
    "            31,  2361,   315,   479, 28855,  1410,     7,  1209,  4454,    71,\n",
    "            39,  3470, 13592,   756,   479, 34587,    33, 11508,   504,  1267,\n",
    "          1175,    11,   158,  2856,   187,  1618,   315,   479, 23551,   636,\n",
    "            21,  1051,   160,    15,    39,  3870,  2453,   136,  6623,  1696,\n",
    "           479,  2107,    12,   180,    12,   279,    34,   576,   409,    80,\n",
    "          6736,    11,   237, 14158,    83,  2856,   479, 28855,    21, 12826,\n",
    "            66, 13089,    30, 15607,    18,  2155,   230, 35378,    42,   353,\n",
    "           479],\n",
    "        [    2, 12815,  5892,  2971,   161,    70,  2891,   227, 18752,     8,\n",
    "          2924, 15136,     8,  2203,   197,    28,  4638,   479,  5095, 33018,\n",
    "          1478,   197,    33,  2998,   984,  1749,     6,   151,   458, 25176,\n",
    "            11,   491,  1913,    77,    37,  2867, 18123,   852,     6,  5736,\n",
    "           384,   108, 21489,   161,   479,   427, 33018,  1478,   956,    55,\n",
    "          1675,   899,     7,  2339,    15,  4952,    71,  5195,  4840,  6197,\n",
    "           479,  5653,  7567,   197,    33,    57,   699,    59,    99,    39,\n",
    "           780,  4988,    21,   608,     6,    26,  5736,   384,   108, 21489,\n",
    "           479,   427,  5628,    34,  1433,  2641,  3770,  1220,  1235,     7,\n",
    "           120,   128, 15605,   593,   108,     7, 15136,     8, 32130,   994,\n",
    "           479]], device='cuda:0')\n",
    "\n",
    "tensor([[    2, 20340, 20434,    58,   576,  4427, 11607,    11,  4290,   479,\n",
    "           820,    12,   180,    12,   279,   313,  1340,    77,  3286,  5932,\n",
    "           479]], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target\n",
    "tensor([[  487,  5649,  1910, 23551,   636,     8,  5716, 28855,    33,   258,\n",
    "            56,  2129,  2012,     7,     5,   191,   479, 23551,   636,  1770,\n",
    "          3870,    11,    10,   130,    12,   180,   432,    42,  1035,    31,\n",
    "          2361,   315,   479, 28855,  1410,     7,  1209,  4454,    71,    39,\n",
    "          3470, 13592,   756,   479, 34587,    33, 11508,   504,  1267,  1175,\n",
    "            11,   158,  2856,   187,  1618,   315,   479, 23551,   636,    21,\n",
    "          1051,   160,    15,    39,  3870,  2453,   136,  6623,  1696,   479,\n",
    "          2107,    12,   180,    12,   279,    34,   576,   409,    80,  6736,\n",
    "            11,   237, 14158,    83,  2856,   479, 28855,    21, 12826,    66,\n",
    "         13089,    30, 15607,    18,  2155,   230, 35378,    42,   353,   479,\n",
    "             2],\n",
    "        [12815,  5892,  2971,   161,    70,  2891,   227, 18752,     8,  2924,\n",
    "         15136,     8,  2203,   197,    28,  4638,   479,  5095, 33018,  1478,\n",
    "           197,    33,  2998,   984,  1749,     6,   151,   458, 25176,    11,\n",
    "           491,  1913,    77,    37,  2867, 18123,   852,     6,  5736,   384,\n",
    "           108, 21489,   161,   479,   427, 33018,  1478,   956,    55,  1675,\n",
    "           899,     7,  2339,    15,  4952,    71,  5195,  4840,  6197,   479,\n",
    "          5653,  7567,   197,    33,    57,   699,    59,    99,    39,   780,\n",
    "          4988,    21,   608,     6,    26,  5736,   384,   108, 21489,   479,\n",
    "           427,  5628,    34,  1433,  2641,  3770,  1220,  1235,     7,   120,\n",
    "           128, 15605,   593,   108,     7, 15136,     8, 32130,   994,   479,\n",
    "             2]], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_lengths\n",
    "tensor([1024, 1024], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_tokens\n",
    "tensor([[  487,  5649,  1910,  ..., 35444, 20921,     2],\n",
    "        [ 2765,   479,  3005,  ...,    12,  5532,     2]], device='cuda:0')\n",
    "\n",
    "tensor([[ 1640, 16256,    43,   250,   806,  1031,     8,   292,    97,    82,\n",
    "            32,  9741,  1462,    71,    10,  7775,   668,  4957,    10, 15906,\n",
    "            11,  3921, 20048,     6,  4788,     4,    20,   790, 14574,     7,\n",
    "           806,  1031,  1599,   221, 14143,     6,     5,   834,  1633,  1036,\n",
    "            13,  4662, 23345,   636,     6,   138,  1565,  4578, 21299,  1851,\n",
    "           139,    26,     4,   221, 14143,    56,    45,    57,  1317,    31,\n",
    "            15,   302,     6,     8,    39,  4025,    23,  4662, 23345,   636,\n",
    "            58,    22,  9547,   154,    13,    10, 16829,    60,  3480, 10515,\n",
    "           305,   863,  8272,   431,     4,   221, 14143,    21,  2047,     7,\n",
    "            33,    57,    23,   184,    19,    39,  1141,     8,   237,  9165,\n",
    "             4,   520,     5,    78,  6065,  2035,    15,     5,  1310,     6,\n",
    "            51,   829, 22757,   690,    59,   549,     5,   284,   189,    33,\n",
    "            57,    66,     9,  1139,     4,   125,    71,  5533,    19,  6774,\n",
    "             6,    22,   405,    34,    57,  3030,    14,   411,   453,     9,\n",
    "             5,   284,    32,    45,  9521,    13,    60,     5,  7896,    83,\n",
    "          2070,  1187,   523,   413,  1833,   641,    26,     4,  1833,   503,\n",
    "            26,    51,    58, 14588,    59,   155,    35,   541,    10,     4,\n",
    "           119,     4,   302,     7,     5,   668,    11,     5,   545,     6,\n",
    "           151,    12, 11636,    12,  2917,   790,     4,  1936,  1812,  6065,\n",
    "          2334,     4,    20,  4750,     9, 17794,     6, 20246,     6, 32576,\n",
    "             8, 35936,  3699,    16, 13390,     5,   400,   668,  1494,     6,\n",
    "             8,    41, 36768,   632,  1263,   165,    16,   145, 14525,   142,\n",
    "             5,   668,    21,  7661,  7775,     6,    10,   488,  2251,   781,\n",
    "            26,     4,    20,  7685,    12,   995,   184,    16,   145,  3032,\n",
    "            25,    10,  1846,  1310,   454,  3725,  1955,    66,     5,  1303,\n",
    "             6,     5,   781,    26,     4,    20,  7896,    83,  2070,  1187,\n",
    "           523,   413,  1833,   641,    26,   668,  5452,    56,  9600, 13682,\n",
    "           159,     5,  8769,   142,     5,   790,    16,   842, 26441,     6,\n",
    "          4100,    19,   117,   668, 14791, 10232,  3277,    15,     5,  1310,\n",
    "             4, 10878,     5,   668,  1494,  1278,    15,   599,   969,  1368,\n",
    "         18575, 13596,    13,   251, 21459,     4, 12051,    26,    24,   362,\n",
    "           484,   722,    13,   668,  1494, 19063,  5875,     8,    10,   668,\n",
    "          4293,    15,    41, 12142, 23954,     7,   836,     5,   668,   223,\n",
    "           797,     6,    37,    26,     4, 36768,  3672, 18497,  4475,  3576,\n",
    "          2911,   677,    26,   117,    65,    34, 10593,    13,   678,  1680,\n",
    "           648,   142,     9,     5,  1836,     8,  2859,     9,     5,   668,\n",
    "             4,  3480,    18,   840, 26298,  1698,  8644,  2379, 10608,     8,\n",
    "          7596,   219,  5470,  1755,  3162,     7,    42,   266,     4,     2]],\n",
    "       device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor([1,     1,     1,     1, 18764,  6080,    32,  2509,    11,  9692,\n",
    "        5955,  5031,  7300,  1809,  3432,     4,    20,  3430,   758,    34,\n",
    "        10522,    57,  9692,    18,   275,   869,    42,   191,     8,    39,\n",
    "        12431,  1672,  8612,    11,     5, 11608,   815,    33,  2037,     5,\n",
    "        2295,     9,  2529,  6080,   813,     4,   635,     6,  7300,  1809,\n",
    "        3432,    16,   157,   802,     9,    23,  9692,     8,     5,  3453,\n",
    "        526,   109,    45,    33,   203,   418,     7,  1930,     4,  5031,\n",
    "        7300,  1809,  3432,    18,  8612,    13,  9692,    11,     5, 11608,\n",
    "        815,    33,  2037,     5,  2295,     9,  3453,   526,  2529,  6080,\n",
    "        479,    20,   971,    12,   180,    12,   279,  1770,  9692,    15,\n",
    "        10,   481,  2937,    31,  5706,    11,  1125,     8,    34,  1008,\n",
    "        365,  1175,    11,   843,  4961,    13,     5,   598,  3145,  5421,\n",
    "        42,  1385,     4,    20,   556,  1008,   148,  3430,    18,   231,\n",
    "        12,   134,  1124,   136, 23545,    11,   395,    18,  5122,   336,\n",
    "        18008,     8,    34,  2208,   823,   843,  9686,    13,    39,   247,\n",
    "        4,  7300,  1809,  3432,  8409,  2314,   148,  3430,    18,   231,\n",
    "        12,   134,  1124,   136, 23545,    11,   395,    18,  5122,   336,\n",
    "        18008,   479,     2], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"untitled.txt\") as f:\n",
    "    for line in f:\n",
    "        s = line.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor([    0, 31339,  4128,  2029,     5, 14305, 10542,    81,  1697,  3474,\n",
    "         2021,    11,  5791, 13560,   187,    94,   502,   479,  1870,     8,\n",
    "            5,   315,   532,  4340,     5,   517,     6,    61,   115,   490,\n",
    "            5,  1883,     7,   997,  3474,  4941,   136, 19544,   479,     2],\n",
    "       device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference input\n",
    "# tensor([[    0, 10169,  1090,  ...,   115,    28,     2],\n",
    "#         [    0, 40589,    35,  ...,  6113, 21194,     2],\n",
    "#         [    1,     1,     0,  ...,    26,     4,     2],\n",
    "#         ...,\n",
    "#         [    1,     1,     1,  ...,   266,     4,     2],\n",
    "#         [    1,     1,     1,  ...,   621,     4,     2],\n",
    "#         [    1,     1,     1,  ...,  1451,     4,     2]], device='cuda:0')\n",
    "\n",
    "# tensor([1024, 1024,  802,  735,  600,  490,  284,  174], device='cuda:0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
